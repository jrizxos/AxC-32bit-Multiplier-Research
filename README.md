# AxC-32bit-Multiplier-Research

In this repository we publish the code used to run the Genetic Algorithm experiments for our paper:<br>
**Design space exploration of partial product reduction stage on 32x32 approximate multipliers**<br>
Not published yet. Submitted for the 13th International Conference on Modern Circuits and Systems Technologies (MOCAST 2024). (updated: 11/02/2023)

Repository Authors:
- Ioannis Rizos
- Georgios Papatheodorou

**For any questions please create an Issue within this repository.**

---

## Study Results
# todo
---

## Requirements

To run our code you need [Python](https://www.python.org/downloads/) installed.
For VHDL synthesis and implementation we use [Cadence Genus](https://www.cadence.com/en_US/home/tools/digital-design-and-signoff/synthesis/genus-synthesis-solution.html), it needs to be installed in your system if you intend to use it.
We tested this program with **Python 3.10.12** and **Cadence Genus 21.10** on **Ubuntu 22.04.2 LTS**.

---

## Setting-up

```
# Clone repository and submodules:
git clone https://github.com/jrizxos/AxC-32bit-Multiplier-Research
cd AxC-32bit-Multiplier-Research
git submodule update --init --recursive

# Install python requirements on your python environment:
pip install -r requirements.txt

# Generate input for evaluator:
cd code\ generation\ tools 
python input_gen.py
mv inp.bin ../cppsim

# Generate library for Genus:
python libmerge.py
mv gf180mcu.lib ../tcl_work_dir

# Compile evaluator:
cd ../cppsim 
make
```

---

## Included results

- To inspect our included pareto fronts, we provide the *utilities.py* module. Simply running it will print statistics about the fronts.
The *get_dataframe* method works on all lists of individuals and returns a pandas dataframe that can be used to do further statistical analysis.
- To get a list of individuals out of a .json file created by *search.py* you can use the *load_raw* method from *score_tree.py*.
- To get the RTL code of any .json file created by *search.py* use the *create_RTL* method from *utilities.py* after loading its contents in a list.

*utilities.py* includes examples of the above in its main code region.

---

## File Structure

```
├── code generation tools            (scripts for automatic generation of code material)
│   ├── axc_wallace_32x32.vhd        (behavioral description of multiplier module, needed by scripts)
│   ├── cpp_gen.py                   (C++ code generator)       
│   ├── findpath.py                  (reverse path finder for AFAs)
│   ├── gf180mcu-pdk                 (gf180mcu-pdk submodule)
│   ├── input_gen.py                 (input generation  script)
│   └── libmerge.py                  (gf180mcu-pdk library merger script)
├── cppsim                           (C++ functional simulator directory)
│   ├── afa.cpp                      (approximate full adder functions)
│   ├── afa.h
│   ├── debug.cpp                    (debug functions)
│   ├── debug.h
│   ├── evaluator.cpp                (MAIN evaluator program)
│   ├── evaluator.h
│   ├── inp.bin                      (inputs file, generated by input_gen.py)
│   ├── Makefile                     (makefile)
│   ├── mul32.cpp                    (32x32 modular multiplier function)
│   ├── mul32.h
│   └── testme.py                    (python-C++ interface test script)
├── highscores.json                  (database for archived individuals, generated by search.py)
├── individual.py                    (individual class)
├── LICENSE                          (license file)
├── mins.json                        (minimum values recorded, for use in NSGA-II, and exact multiplier)
├── pareto.json                    	 (search output file, generated by search.py)
├── pareto-final.json                (final pareto for our results)
├── pareto-optimized.json            (optimized pareto for our results)
├── README.md                        (readme file)
├── score_tree.py                    (search tree methods)
├── search.py                        (MAIN search program)
├── tcl_helper.py                    (tcl script helper)
├── tcl_work_dir                     (tcl script working directory)
│   ├── gf180mcu.lib                 (gf180mcu-pdk library, generated by libmerge.py)
│   ├── main_high.tcl                (main tcl script with high effort setting)
│   ├── main_low.tcl                 (main tcl script with low effort setting)
│   ├──vhdl                          (multiplier VHDL code directory)
│   │   ├── axc_wallace.vhd
│   │   ├── ...
│   │   └── out_reg.vhd
│   ├── tcl_out                      (Genus report output directory)
│   └── temp                         (temporary Genus projects directory, safe to delete contents after program finishes)
└── utilities.py                     (utilities to handle the study of produced data)
```

---

## Using the code

- *search.py* can be used to start a new search run. The program prints the process at the CLI as it runs and stores
current pareto and all evaluated individuals at pareto.json and highscores.json. This happens at the end of every generation.
- To evaluate your own individuals without conducting search, it is recommended that you use the *run_static* method in *search.py*
with a list of individuals as argument. It will overwrite current highscores.json with the results.

---

# search.py parameters:

- **POP_N**: number of individuals in population
- **BST_N**: number of best individuals to select.
- **CLD_N**: number of children to make each generation (for NSGA-II this being equal to POP_N is recommended).
- **GEN_N**: max number of generations allowed.
- **MUT_P**: probability of mutation.
- **random.seed()**: set a seed in order to get the same results each time.
- **MAX_PROC**: sets the number of maximum parallel evaluation processes called by search.
- **PROC_TIM**: max seconds to wait for a process, if it gets stuck.
- **TCL_DEBUG**: (True/False) whether or not to print debug info from Genus commands (to debug Genus MAX_PROC=1 is recommended, as they all print at the same time).
- **EVL_DEBUG**: (True/False) whether or not to print extra debug info from this program.

---

## Known Problems

- Compiled evaluator executable might not work properly on all configurations of Windows. This has to do with some 'binary mode' of Windows pipes.

---

## Appendix A: The individual Class

GA's are centered around a population of individuals, to implement that we created a storage class
called individual. An individual for this program is essentially the high level description for
an approximate multiplier. It's fields are:

- **vars**: (list of ints) the values for each variable.
- **mae**: (int) mean average error produced by this multiplier.
- **area**: (float) physical area of this individual (micrometers).
- **time**: (float) physical delay slack of this individual (picoseconds).
- **power**: (float) physical power consumption of this individual (Watts).
- **loaded_id**: (float) a simple name for this individual.

An individual is initialized by invoking:

```
name = 'ind-0' # a name, must be unique in a list of individuals that will be evaluated in parallel
indy = individual(vars, name) # where vars is the list of initial values for each variable
#or
indy = individual(None, name) # the individual will have randomized initial values for each variable
```

All other values are initialized to None. They are set to the correct values when

```
run_evaluation(indy.vars, indy.loaded_id)
```

is called in *search.py*. To evaluate your own individual/s we recommend using:

```
indx = individual(varsx, 'ind-x')
# ...
indy = individual(varsy, 'ind-y')
IUT = [indx, ..., indy]
run_static(IUT)
```
in *search.py*. This will evaluate them and store their values in *highscores.json*.

---

## Appendix B: The score_tree module

The *score_tree.py* module is a simple search tree data structure, used to quickly assert if an individual has been evaluated in the past and skip its evaluation.
It operates using a Node class, with one Node as the TREE_ROOT and others as children. Each Node can hold a variable value and have other Nodes as children. The
root is at depth 0, children at depth 1 hold the first variable value for the individuals stored in the tree, children at depth 2 hold the second, etc until depth 918
which is the number of values per individual (defined at individual.VAR_N). Children at depth 918 have their Node.leaf set to true so that they know they are leafs.
An individual is placed in the tree as a path from the root to a leaf at depth 918. At each depth a new Node is placed only if the Node with the value for that depth
does not already exist. So each unique possible path on the tree corresponds to a unique individual stored on the tree.

The provided methods are:
- **find_individual**: finds an idividual on the tree, returns none if it does not exist or the individual if it exists
- **evaluated_individual**: finds an individual on the tree and asserts if it was evaluated, returns true or false
- **place_individual**: places a new individual on the tree
- **load_tree**: loads a tree from a .json file created by *search.py*, returns an empty root if the file does not exist or is empty
- **store_tree**: stores all the individuals on a tree at a .json file
- **load_raw**: loads a the individuals from a .json file created by *search.py* as a list (instead of a tree)
- **store_raw**: stores a list of individuals in a .json file
